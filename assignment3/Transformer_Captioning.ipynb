{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This mounts your Google Drive to the Colab VM.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
    "# assignment folder, e.g. 'cs231n/assignments/assignment3/'\n",
    "FOLDERNAME = None\n",
    "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# Now that we've mounted your Drive, this ensures that\n",
    "# the Python interpreter of the Colab VM can load\n",
    "# python files from within it.\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "# This downloads the COCO dataset to your Drive\n",
    "# if it doesn't already exist.\n",
    "%cd /content/drive/My\\ Drive/$FOLDERNAME/cs231n/datasets/\n",
    "!bash get_datasets.sh\n",
    "%cd /content/drive/My\\ Drive/$FOLDERNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Image Captioning with Transformers\n",
    "You have now implemented a vanilla RNN and for the task of image captioning. In this notebook you will implement key pieces of a transformer decoder to accomplish the same task.\n",
    "\n",
    "**NOTE:** This notebook will be primarily written in PyTorch rather than NumPy, unlike the RNN notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# Setup cell.\n",
    "import time, os, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cs231n.gradient_check import eval_numerical_gradient, eval_numerical_gradient_array\n",
    "from cs231n.transformer_layers import *\n",
    "from cs231n.captioning_solver_transformer import CaptioningSolverTransformer\n",
    "from cs231n.classifiers.transformer import CaptioningTransformer\n",
    "from cs231n.coco_utils import load_coco_data, sample_coco_minibatch, decode_captions\n",
    "from cs231n.image_utils import image_from_url\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # Set default size of plots.\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO Dataset\n",
    "As in the previous notebooks, we will use the COCO dataset for captioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base dir  /Users/akira/Documents/learning/deeplearning/stanford_cs232n_2021/assignment3/cs231n/datasets/coco_captioning\n",
      "train_captions <class 'numpy.ndarray'> (400135, 17) int32\n",
      "train_image_idxs <class 'numpy.ndarray'> (400135,) int32\n",
      "val_captions <class 'numpy.ndarray'> (195954, 17) int32\n",
      "val_image_idxs <class 'numpy.ndarray'> (195954,) int32\n",
      "train_features <class 'numpy.ndarray'> (82783, 512) float32\n",
      "val_features <class 'numpy.ndarray'> (40504, 512) float32\n",
      "idx_to_word <class 'list'> 1004\n",
      "word_to_idx <class 'dict'> 1004\n",
      "train_urls <class 'numpy.ndarray'> (82783,) <U63\n",
      "val_urls <class 'numpy.ndarray'> (40504,) <U63\n"
     ]
    }
   ],
   "source": [
    "# Load COCO data from disk into a dictionary.\n",
    "data = load_coco_data(pca_features=True)\n",
    "\n",
    "# Print out all the keys and values from the data dictionary.\n",
    "for k, v in data.items():\n",
    "    if type(v) == np.ndarray:\n",
    "        print(k, type(v), v.shape, v.dtype)\n",
    "    else:\n",
    "        print(k, type(v), len(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "As you have seen, RNNs are incredibly powerful but often slow to train. Further, RNNs struggle to encode long-range dependencies (though LSTMs are one way of mitigating the issue). In 2017, Vaswani et al introduced the Transformer in their paper [\"Attention Is All You Need\"](https://arxiv.org/abs/1706.03762) to a) introduce parallelism and b) allow models to learn long-range dependencies. The paper not only led to famous models like BERT and GPT in the natural language processing community, but also an explosion of interest across fields, including vision. While here we introduce the model in the context of image captioning, the idea of attention itself is much more general.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqPMDm4F9m0v"
   },
   "source": [
    "# Transformer: Multi-Headed Attention\n",
    "\n",
    "### Dot-Product Attention\n",
    "\n",
    "Recall that attention can be viewed as an operation on a query $q\\in\\mathbb{R}^d$, a set of value vectors $\\{v_1,\\dots,v_n\\}, v_i\\in\\mathbb{R}^d$, and a set of key vectors $\\{k_1,\\dots,k_n\\}, k_i \\in \\mathbb{R}^d$, specified as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "c = \\sum_{i=1}^{n} v_i \\alpha_i &\\alpha_i = \\frac{\\exp(k_i^\\top q)}{\\sum_{j=1}^{n} \\exp(k_j^\\top q)} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\alpha_i$ are frequently called the \"attention weights\", and the output $c\\in\\mathbb{R}^d$ is a correspondingly weighted average over the value vectors.\n",
    "\n",
    "### Self-Attention\n",
    "In Transformers, we perform self-attention, which means that the values, keys and query are derived from the input $X \\in \\mathbb{R}^{\\ell \\times d}$, where $\\ell$ is our sequence length. Specifically, we learn parameter matrices $V,K,Q \\in \\mathbb{R}^{d\\times d}$ to map our input $X$ as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "v_i = Vx_i\\ \\ i \\in \\{1,\\dots,\\ell\\}\\\\\n",
    "k_i = Kx_i\\ \\ i \\in \\{1,\\dots,\\ell\\}\\\\\n",
    "q_i = Qx_i\\ \\ i \\in \\{1,\\dots,\\ell\\}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Headed Scaled Dot-Product Attention\n",
    "In the case of multi-headed attention, we learn a parameter matrix for each head, which gives the model more expressivity to attend to different parts of the input. Let $h$ be number of heads, and $Y_i$ be the attention output of head $i$. Thus we learn individual matrices $Q_i$, $K_i$ and $V_i$. To keep our overall computation the same as the single-headed case, we choose $Q_i \\in \\mathbb{R}^{d\\times d/h}$, $K_i \\in \\mathbb{R}^{d\\times d/h}$ and $V_i \\in \\mathbb{R}^{d\\times d/h}$. Adding in a scaling term $\\frac{1}{\\sqrt{d/h}}$ to our simple dot-product attention above, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation} \\label{qkv_eqn}\n",
    "Y_i = \\text{softmax}\\bigg(\\frac{(XQ_i)(XK_i)^\\top}{\\sqrt{d/h}}\\bigg)(XV_i)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $Y_i\\in\\mathbb{R}^{\\ell \\times d/h}$, where $\\ell$ is our sequence length.\n",
    "\n",
    "In our implementation, we then apply dropout here (though in practice it could be used at any step):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Y_i = \\text{dropout}(Y_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, then the output of the self-attention is a linear transformation of the concatenation of the heads:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "Y = [Y_1;\\dots;Y_h]A\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "were $A \\in\\mathbb{R}^{d\\times d}$ and $[Y_1;\\dots;Y_h]\\in\\mathbb{R}^{\\ell \\times d}$.\n",
    "\n",
    "Implement multi-headed scaled dot-product attention in the `MultiHeadAttention` class in the file `cs231n/transformer_layers.py`. The code below will check your implementation. The relative error should be less than 1e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_attn_output error:  0.0003772742211599121\n",
      "masked_self_attn_output error:  0.0001526367643724865\n",
      "attn_output error:  0.00035224630317522767\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(231)\n",
    "\n",
    "# Choose dimensions such that they are all unique for easier debugging:\n",
    "# Specifically, the following values correspond to N=1, H=2, T=3, E//H=4, and E=8.\n",
    "batch_size = 1\n",
    "sequence_length = 3\n",
    "embed_dim = 8\n",
    "attn = MultiHeadAttention(embed_dim, num_heads=2)\n",
    "\n",
    "# Self-attention.\n",
    "data = torch.randn(batch_size, sequence_length, embed_dim)\n",
    "self_attn_output = attn(query=data, key=data, value=data)\n",
    "\n",
    "# Masked self-attention.\n",
    "mask = torch.randn(sequence_length, sequence_length) < 0.5\n",
    "masked_self_attn_output = attn(query=data, key=data, value=data, attn_mask=mask)\n",
    "\n",
    "# Attention using two inputs.\n",
    "other_data = torch.randn(batch_size, sequence_length, embed_dim)\n",
    "attn_output = attn(query=data, key=other_data, value=other_data)\n",
    "\n",
    "expected_self_attn_output = np.asarray([[\n",
    "[-0.2494,  0.1396,  0.4323, -0.2411, -0.1547,  0.2329, -0.1936,\n",
    "          -0.1444],\n",
    "         [-0.1997,  0.1746,  0.7377, -0.3549, -0.2657,  0.2693, -0.2541,\n",
    "          -0.2476],\n",
    "         [-0.0625,  0.1503,  0.7572, -0.3974, -0.1681,  0.2168, -0.2478,\n",
    "          -0.3038]]])\n",
    "\n",
    "expected_masked_self_attn_output = np.asarray([[\n",
    "[-0.1347,  0.1934,  0.8628, -0.4903, -0.2614,  0.2798, -0.2586,\n",
    "          -0.3019],\n",
    "         [-0.1013,  0.3111,  0.5783, -0.3248, -0.3842,  0.1482, -0.3628,\n",
    "          -0.1496],\n",
    "         [-0.2071,  0.1669,  0.7097, -0.3152, -0.3136,  0.2520, -0.2774,\n",
    "          -0.2208]]])\n",
    "\n",
    "expected_attn_output = np.asarray([[\n",
    "[-0.1980,  0.4083,  0.1968, -0.3477,  0.0321,  0.4258, -0.8972,\n",
    "          -0.2744],\n",
    "         [-0.1603,  0.4155,  0.2295, -0.3485, -0.0341,  0.3929, -0.8248,\n",
    "          -0.2767],\n",
    "         [-0.0908,  0.4113,  0.3017, -0.3539, -0.1020,  0.3784, -0.7189,\n",
    "          -0.2912]]])\n",
    "\n",
    "print('self_attn_output error: ', rel_error(expected_self_attn_output, self_attn_output.detach().numpy()))\n",
    "print('masked_self_attn_output error: ', rel_error(expected_masked_self_attn_output, masked_self_attn_output.detach().numpy()))\n",
    "print('attn_output error: ', rel_error(expected_attn_output, attn_output.detach().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcDBRnqL9m0w"
   },
   "source": [
    "# Positional Encoding\n",
    "\n",
    "While transformers are able to easily attend to any part of their input, the attention mechanism has no concept of token order. However, for many tasks (especially natural language processing), relative token order is very important. To recover this, the authors add a positional encoding to the embeddings of individual word tokens.\n",
    "\n",
    "Let us define a matrix $P \\in \\mathbb{R}^{l\\times d}$, where $P_{ij} = $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{cases}\n",
    "\\text{sin}\\left(i \\cdot 10000^{-\\frac{j}{d}}\\right) & \\text{if j is even} \\\\\n",
    "\\text{cos}\\left(i \\cdot 10000^{-\\frac{(j-1)}{d}}\\right) & \\text{otherwise} \\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than directly passing an input $X \\in \\mathbb{R}^{l\\times d}$ to our network, we instead pass $X + P$.\n",
    "\n",
    "Implement this layer in `PositionalEncoding` in `cs231n/transformer_layers.py`. Once you are done, run the following to perform a simple test of your implementation. You should see errors on the order of `e-3` or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pe_output error:  0.00010421011374914356\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(231)\n",
    "\n",
    "batch_size = 1\n",
    "sequence_length = 2\n",
    "embed_dim = 6\n",
    "data = torch.randn(batch_size, sequence_length, embed_dim)\n",
    "\n",
    "pos_encoder = PositionalEncoding(embed_dim)\n",
    "output = pos_encoder(data)\n",
    "\n",
    "expected_pe_output = np.asarray([[[-1.2340,  1.1127,  1.6978, -0.0865, -0.0000,  1.2728],\n",
    "                                  [ 0.9028, -0.4781,  0.5535,  0.8133,  1.2644,  1.7034]]])\n",
    "\n",
    "print('pe_output error: ', rel_error(expected_pe_output, output.detach().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "# Inline Question 1\n",
    "\n",
    "Several key design decisions were made in designing the scaled dot product attention we introduced above. Explain why the following choices were beneficial:\n",
    "1. Using multiple attention heads as opposed to one.\n",
    "2. Dividing by $\\sqrt{d/h}$ before applying the softmax function. Recall that $d$ is the feature dimension and $h$ is the number of heads.\n",
    "3. Adding a linear transformation to the output of the attention operation. What would happen if we were to stack attention operations directly?\n",
    "\n",
    "Only one or two sentences per choice is necessary, but be sure to be specific in addressing what would have happened without each given implementation detail, why such a situation would be suboptimal, and how the proposed implementation improves the situation.\n",
    "\n",
    "**Your Answer:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit Transformer Captioning Model on Small Data\n",
    "Run the following to overfit the Transformer-based captioning model on the same small dataset as we used for the RNN previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base dir  /Users/akira/Documents/learning/deeplearning/stanford_cs232n_2021/assignment3/cs231n/datasets/coco_captioning\n",
      "(Iteration 1 / 200) loss: 5.023862\n",
      "(Iteration 11 / 200) loss: 2.838943\n",
      "(Iteration 21 / 200) loss: 1.969247\n",
      "(Iteration 31 / 200) loss: 1.578315\n",
      "(Iteration 41 / 200) loss: 1.207538\n",
      "(Iteration 51 / 200) loss: 1.058016\n",
      "(Iteration 61 / 200) loss: 0.726696\n",
      "(Iteration 71 / 200) loss: 0.660734\n",
      "(Iteration 81 / 200) loss: 0.445335\n",
      "(Iteration 91 / 200) loss: 0.345738\n",
      "(Iteration 101 / 200) loss: 0.256774\n",
      "(Iteration 111 / 200) loss: 0.122006\n",
      "(Iteration 121 / 200) loss: 0.085906\n",
      "(Iteration 131 / 200) loss: 0.080269\n",
      "(Iteration 141 / 200) loss: 0.064477\n",
      "(Iteration 151 / 200) loss: 0.061428\n",
      "(Iteration 161 / 200) loss: 0.038984\n",
      "(Iteration 171 / 200) loss: 0.042230\n",
      "(Iteration 181 / 200) loss: 0.021492\n",
      "(Iteration 191 / 200) loss: 0.025071\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(231)\n",
    "np.random.seed(231)\n",
    "\n",
    "data = load_coco_data(max_train=50)\n",
    "\n",
    "transformer = CaptioningTransformer(\n",
    "          word_to_idx=data['word_to_idx'],\n",
    "          input_dim=data['train_features'].shape[1],\n",
    "          wordvec_dim=256,\n",
    "          num_heads=2,\n",
    "          num_layers=2,\n",
    "          max_length=30\n",
    "        )\n",
    "\n",
    "\n",
    "transformer_solver = CaptioningSolverTransformer(transformer, data, idx_to_word=data['idx_to_word'],\n",
    "           num_epochs=100,\n",
    "           batch_size=25,\n",
    "           learning_rate=0.001,\n",
    "           verbose=True, print_every=10,\n",
    "         )\n",
    "\n",
    "transformer_solver.train()\n",
    "\n",
    "# Plot the training losses.\n",
    "plt.plot(transformer_solver.loss_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print final training loss. You should see a final loss of less than 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "transformer_final_training_loss",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss:  0.025776176\n"
     ]
    }
   ],
   "source": [
    "print('Final loss: ', transformer_solver.loss_history[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Sampling at Test Time\n",
    "The sampling code has been written for you. You can simply run the following to compare with the previous results with the RNN. As before the training results should be much better than the validation set results, given how little data we trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ConnectionResetError",
     "evalue": "[Errno 54] Connection reset by peer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bw/0ysxvxj95kvg94vzv34y4s240000gn/T/ipykernel_41803/1860056790.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgt_caption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_caption\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_captions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_captions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Skip missing URLs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/learning/deeplearning/stanford_cs232n_2021/assignment3/cs231n/image_utils.py\u001b[0m in \u001b[0;36mimage_from_url\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \"\"\"\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkstemp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    535\u001b[0m                                   '_open', req)\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionResetError\u001b[0m: [Errno 54] Connection reset by peer"
     ]
    }
   ],
   "source": [
    "# If you get an error, the URL just no longer exists, so don't worry!\n",
    "# You can re-sample as many times as you want.\n",
    "for split in ['train', 'val']:\n",
    "    minibatch = sample_coco_minibatch(data, split=split, batch_size=2)\n",
    "    gt_captions, features, urls = minibatch\n",
    "    gt_captions = decode_captions(gt_captions, data['idx_to_word'])\n",
    "\n",
    "    sample_captions = transformer.sample(features, max_length=30)\n",
    "    sample_captions = decode_captions(sample_captions, data['idx_to_word'])\n",
    "\n",
    "    for gt_caption, sample_caption, url in zip(gt_captions, sample_captions, urls):\n",
    "        img = image_from_url(url)\n",
    "        # Skip missing URLs.\n",
    "        if img is None: continue\n",
    "        plt.imshow(img)            \n",
    "        plt.title('%s\\n%s\\nGT:%s' % (split, sample_caption, gt_caption))\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
